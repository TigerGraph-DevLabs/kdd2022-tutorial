{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network\n",
    "## Notebook 3\n",
    "\n",
    "In this notebook, we will define, train, and test a Graph Neural Network to predict sale prices of NFTs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to TigerGraph Database\n",
    "\n",
    "The code block below connects to a TigerGraph database. Make sure to change the authentication details in order for you to connect to the instance successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg\n",
    "\n",
    "conn = tg.TigerGraphConnection(\"http://3.22.188.182\", graphname=\"KDD_2022_NFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tg_fastRP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = conn.gds.featurizer()\n",
    "\n",
    "f.installAlgorithm(\"tg_fastRP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"v_type\": [\"Category\", \"NFT_Collection\", \"NFT\"], \n",
    "          \"e_type\": [\"COLLECTION_HAS_NFT\", \"CATEGORY_HAS_NFT\", \"NFT_IN_CATEGORY\", \"NFT_IN_COLLECTION\"], \n",
    "          \"weights\": \"1,2,4\", \n",
    "          \"beta\": -0.1,\n",
    "          \"k\": 3,\n",
    "          \"reduced_dim\": 64, \n",
    "          \"sampling_constant\": 3,\n",
    "          \"random_seed\": 42,\n",
    "          \"print_accum\": False,\n",
    "          \"result_attr\": \"fastrp_embedding\"}\n",
    "\n",
    "f.runAlgorithm(\"tg_fastRP\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExprFunctions=\"\"  # For enterprise users, please use the link you received.\n",
    "ExprUtil=\"\"  # For enterprise users, please use the link you received.\n",
    "#conn.installUDF(ExprFunctions, ExprUtil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gds.configureKafka(kafka_address=\"kaf.kdd.tigergraphlabs.com:19092\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = conn.gds.neighborLoader(\n",
    "    v_in_feats={\"Transaction\": [\"seller_k_size\", \"buyer_k_size\"], \n",
    "                \"NFT_User\": [\"pagerank\", \"kcore_size\"], \n",
    "                \"NFT\": [\"fastrp_embedding\"], \n",
    "                \"NFT_Collection\": [\"fastrp_embedding\"], \n",
    "                \"Category\": [\"fastrp_embedding\"]},\n",
    "    v_out_labels={\"Transaction\": [\"usd_price\"]},\n",
    "    v_extra_feats={\"Transaction\":  [\"train\"]},\n",
    "    filter_by={\"Transaction\": \"train\"},\n",
    "    shuffle=True,\n",
    "    batch_size=2048,\n",
    "    buffer_size=4,\n",
    "    add_self_loop=True,\n",
    "    reverse_edge=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Transaction', 'NFT_User', 'NFT', 'NFT_Collection', 'Category'], [('Transaction', 'NFT_SOLD_BY', 'NFT_User'), ('Transaction', 'NFT_BOUGHT_BY', 'NFT_User'), ('Transaction', 'FOR_SALE_OF', 'NFT'), ('NFT', 'HAD_TRANSACTION', 'Transaction'), ('NFT', 'NFT_IN_COLLECTION', 'NFT_Collection'), ('NFT', 'NFT_IN_CATEGORY', 'Category'), ('NFT_User', 'USER_SOLD_NFT', 'Transaction'), ('NFT_User', 'USER_SOLD_TO', 'NFT_User'), ('NFT_User', 'USER_BOUGHT_FROM', 'NFT_User'), ('NFT_User', 'USER_BOUGHT_NFT', 'Transaction')])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.metadata())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a normal (homogeneous) GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, num_layers, out_dim, dropout, hidden_dim, num_heads\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_units = (-1, -1) if i == 0 else hidden_dim * num_heads\n",
    "            out_units = out_dim if i == (num_layers - 1) else hidden_dim\n",
    "            heads = 1 if i == (num_layers - 1) else num_heads\n",
    "            self.layers.append(\n",
    "                GATConv(in_units, out_units, heads=heads, dropout=dropout)\n",
    "            )\n",
    "        self.double()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = x.float()\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.layers[-1](x, edge_index)\n",
    "        return x\n",
    "    \n",
    "model = GAT(\n",
    "    num_layers=2,\n",
    "    out_dim=1,\n",
    "    dropout=0.8,\n",
    "    hidden_dim=8,\n",
    "    num_heads=4,\n",
    ")\n",
    "\n",
    "# Convert it to a heterogeneous model. See https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero for details.\n",
    "model = to_hetero(model, batch.metadata(), aggr='mul').to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "mae = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/gnn_training'+str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 LOSS: 84.1789609004902 MAE: 84.53867048515747\n",
      "EPOCH: 1 LOSS: 84.07659451301298 MAE: 84.43636703472662\n",
      "EPOCH: 2 LOSS: 83.41138895810124 MAE: 83.77127642621342\n",
      "EPOCH: 3 LOSS: 83.96139434334498 MAE: 84.32050446430317\n",
      "EPOCH: 4 LOSS: 82.09328605267515 MAE: 82.45219914196134\n",
      "EPOCH: 5 LOSS: 81.06711912585138 MAE: 81.42538688487127\n",
      "EPOCH: 6 LOSS: 82.25617711826577 MAE: 82.61477320558305\n",
      "EPOCH: 7 LOSS: 82.2723330178559 MAE: 82.63043146365384\n",
      "EPOCH: 8 LOSS: 83.31271458326462 MAE: 83.66995472163757\n",
      "EPOCH: 9 LOSS: 81.5533396259144 MAE: 81.90969251901369\n",
      "EPOCH: 10 LOSS: 82.6070436670344 MAE: 82.9611001658151\n",
      "EPOCH: 11 LOSS: 82.88955156722217 MAE: 83.24226798438262\n",
      "EPOCH: 12 LOSS: 82.67016822636941 MAE: 83.0194979082486\n",
      "EPOCH: 13 LOSS: 83.79682331829092 MAE: 84.14384375165265\n",
      "EPOCH: 14 LOSS: 80.4344199616139 MAE: 80.77845245076306\n",
      "EPOCH: 15 LOSS: 83.48354590714946 MAE: 83.82721595189226\n",
      "EPOCH: 16 LOSS: 82.61014725372442 MAE: 82.95431615053143\n",
      "EPOCH: 17 LOSS: 82.661893742361 MAE: 83.00846400512489\n",
      "EPOCH: 18 LOSS: 82.18177704079065 MAE: 82.5336890626295\n",
      "EPOCH: 19 LOSS: 78.82222487123461 MAE: 79.18128785967671\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    epochLoss = 0\n",
    "    epochMae = 0\n",
    "\n",
    "    j = 0\n",
    "    for batch in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        mask = batch[\"Transaction\"].train\n",
    "        loss = F.smooth_l1_loss(out[\"Transaction\"][mask].flatten(), batch[\"Transaction\"].y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epochLoss += loss.item()\n",
    "        batchMae = mae(out[\"Transaction\"][mask].flatten(), batch[\"Transaction\"].y[mask])\n",
    "        epochMae += batchMae.item()\n",
    "        #print(\"Batch:\", j, \"Loss:\", loss.item(), \"MAE:\", batchMae.item())\n",
    "\n",
    "                # ...log the running loss\n",
    "        writer.add_scalar('training loss',\n",
    "                        loss.item(),\n",
    "                        i * train_loader.num_batches + j)\n",
    "        writer.add_scalar('training mae',\n",
    "                          batchMae.item(),\n",
    "                          i * train_loader.num_batches + j)\n",
    "\n",
    "        j += 1\n",
    "    print(\"EPOCH:\", i, \"LOSS:\", epochLoss / train_loader.num_batches, \"MAE:\", epochMae / train_loader.num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n"
     ]
    }
   ],
   "source": [
    "test_loader = conn.gds.neighborLoader(\n",
    "    v_in_feats={\"Transaction\": [\"seller_k_size\", \"buyer_k_size\"], \n",
    "                \"NFT_User\": [\"pagerank\", \"kcore_size\"], \n",
    "                \"NFT\": [\"fastrp_embedding\"], \n",
    "                \"NFT_Collection\": [\"fastrp_embedding\"], \n",
    "                \"Category\": [\"fastrp_embedding\"]},\n",
    "    v_out_labels={\"Transaction\": [\"usd_price\"]},\n",
    "    v_extra_feats={\"Transaction\":  [\"test\"]},\n",
    "    filter_by={\"Transaction\": \"test\"},\n",
    "    shuffle=False,\n",
    "    batch_size=2048,\n",
    "    add_self_loop=True,\n",
    "    reverse_edge=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 93.36157755388801 MAE: 93.75959714282766\n"
     ]
    }
   ],
   "source": [
    "totLoss = 0\n",
    "totMAE = 0\n",
    "for batch in test_loader:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        mask = batch[\"Transaction\"].test\n",
    "        loss = F.smooth_l1_loss(out[\"Transaction\"][mask].flatten(), batch[\"Transaction\"].y[mask])\n",
    "    totMAE += mae(out[\"Transaction\"][mask].flatten(), batch[\"Transaction\"].y[mask]).item()\n",
    "    totLoss += loss.item()\n",
    "print(\"LOSS:\", totLoss / test_loader.num_batches, \"MAE:\", totMAE / test_loader.num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TigerGraph Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "58e1c476a485e41cfbe41589baaac1849e255b67efca409760b0ec34d7f4c191"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
