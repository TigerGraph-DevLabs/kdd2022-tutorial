{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "conn = tg.TigerGraphConnection(\"http://3.22.188.182\", graphname=\"KDD_2022_NFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb#ch0000001?line=0'>1</a>\u001b[0m splitter \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgds\u001b[39m.\u001b[39;49mvertexSplitter(v_types\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mTransaction\u001b[39;49m\u001b[39m\"\u001b[39;49m], train\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m, test\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/gds/gds.py:923\u001b[0m, in \u001b[0;36mGDS.vertexSplitter\u001b[0;34m(self, v_types, timeout, **split_ratios)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvertexSplitter\u001b[39m(\u001b[39mself\u001b[39m, v_types: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, timeout: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m600000\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msplit_ratios):\n\u001b[1;32m    879\u001b[0m     \u001b[39m\"\"\"Get a vertex splitter that splits vertices into at most 3 parts randomly.\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[39m    The split results are stored in the provided vertex attributes. Each boolean attribute\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39m            Timeout value for the operation. Defaults to 600000.\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m     \u001b[39mreturn\u001b[39;00m RandomVertexSplitter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconn, v_types, timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_ratios)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/gds/splitters.py:131\u001b[0m, in \u001b[0;36mRandomVertexSplitter.__init__\u001b[0;34m(self, conn, v_types, timeout, **split_ratios)\u001b[0m\n\u001b[1;32m    129\u001b[0m     v_types \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetVertexTypes()\n\u001b[1;32m    130\u001b[0m \u001b[39m# TODO: Check if attributes exist in database. If not, raise error or create\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(conn, query_path, timeout, v_types, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_ratios)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/gds/splitters.py:29\u001b[0m, in \u001b[0;36mBaseRandomSplitter.__init__\u001b[0;34m(self, conn, query_path, timeout, schema_types, **split_ratios)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_ratios \u001b[39m=\u001b[39m split_ratios\n\u001b[1;32m     28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph \u001b[39m=\u001b[39m conn\n\u001b[0;32m---> 29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_name \u001b[39m=\u001b[39m install_query_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, query_path)\n\u001b[1;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout \u001b[39m=\u001b[39m timeout\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema_types \u001b[39m=\u001b[39m schema_types\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/gds/utilities.py:120\u001b[0m, in \u001b[0;36minstall_query_file\u001b[0;34m(conn, file_path, replace, distributed, force)\u001b[0m\n\u001b[1;32m    118\u001b[0m     query_name \u001b[39m=\u001b[39m query_name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m{QUERYSUFFIX}\u001b[39;00m\u001b[39m\"\u001b[39m, replace[\u001b[39m\"\u001b[39m\u001b[39m{QUERYSUFFIX}\u001b[39;00m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    119\u001b[0m \u001b[39m# If query is already installed, skip unless force install.\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mif\u001b[39;00m is_query_installed(conn, query_name):\n\u001b[1;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m force:\n\u001b[1;32m    122\u001b[0m         \u001b[39m#TODO: Drop query.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/gds/utilities.py:96\u001b[0m, in \u001b[0;36mis_query_installed\u001b[0;34m(conn, query_name)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_query_installed\u001b[39m(conn: \u001b[39m\"\u001b[39m\u001b[39mTigerGraphConnection\u001b[39m\u001b[39m\"\u001b[39m, query_name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[39m#If the query already installed return true\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGET /query/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(conn\u001b[39m.\u001b[39mgraphname, query_name)\n\u001b[0;32m---> 96\u001b[0m     queries \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetInstalledQueries()\n\u001b[1;32m     97\u001b[0m     \u001b[39mreturn\u001b[39;00m target \u001b[39min\u001b[39;00m queries\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/pyTigerGraphQuery.py:38\u001b[0m, in \u001b[0;36mpyTigerGraphQuery.getInstalledQueries\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetInstalledQueries\u001b[39m(\u001b[39mself\u001b[39m, fmt: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpy\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mdict\u001b[39m, \u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpd.DataFrame\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     22\u001b[0m     \u001b[39m\"\"\"Returns a list of installed queries.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m    TODO Return with query name as key rather than REST endpoint as key?\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetEndpoints(dynamic\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     40\u001b[0m         \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mdumps(ret)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/pyTigerGraphSchema.py:167\u001b[0m, in \u001b[0;36mpyTigerGraphSchema.getEndpoints\u001b[0;34m(self, builtin, dynamic, static)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m dyn:\n\u001b[1;32m    166\u001b[0m     eps \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 167\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(url \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdynamic=true\u001b[39;49m\u001b[39m\"\u001b[39;49m, resKey\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    168\u001b[0m     \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m res:\n\u001b[1;32m    169\u001b[0m         \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39m\"\u001b[39m\u001b[39m^GET /query/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraphname, ep):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/pyTigerGraphBase.py:248\u001b[0m, in \u001b[0;36mpyTigerGraphBase._get\u001b[0;34m(self, url, authMode, headers, resKey, skipCheck, params)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m, authMode: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m, headers: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, resKey: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         skipCheck: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, params: Union[\u001b[39mdict\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mdict\u001b[39m, \u001b[39mlist\u001b[39m]:\n\u001b[1;32m    228\u001b[0m     \u001b[39m\"\"\"Generic GET method.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m        The (relevant part of the) response from the request (as a dictionary).\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m   \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_req(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, authMode, headers, \u001b[39mNone\u001b[39;49;00m, resKey, skipCheck, params)\n\u001b[1;32m    249\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/pyTigerGraphBase.py:206\u001b[0m, in \u001b[0;36mpyTigerGraphBase._req\u001b[0;34m(self, method, url, authMode, headers, data, resKey, skipCheck, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m     _data \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39museCert \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcertPath \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mrequest(method, url, headers\u001b[39m=\u001b[39;49m_headers, data\u001b[39m=\u001b[39;49m_data, params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    207\u001b[0m         verify\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    208\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mrequest(method, url, headers\u001b[39m=\u001b[39m_headers, data\u001b[39m=\u001b[39m_data, params\u001b[39m=\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    396\u001b[0m         conn\u001b[39m.\u001b[39mrequest_chunked(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[1;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBrokenPipeError\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/urllib3/connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (six\u001b[39m.\u001b[39mensure_str(k\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m headers):\n\u001b[1;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/http/client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[1;32m   1283\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1284\u001b[0m     \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/http/client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1279\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1280\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/http/client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1038\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer)\n\u001b[1;32m   1039\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(message_body, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1046\u001b[0m         \u001b[39m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m         \u001b[39m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m         \u001b[39m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/http/client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 980\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    981\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m         \u001b[39mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     extra_kw[\u001b[39m\"\u001b[39m\u001b[39msocket_options\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket_options\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConnection to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m timed out. (connect timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m     84\u001b[0m         sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m     sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m sock\n\u001b[1;32m     88\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splitter = conn.gds.vertexSplitter(v_types=[\"Transaction\"], train=0.8, test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting vertices...\n",
      "Vertex split finished successfully.\n"
     ]
    }
   ],
   "source": [
    "splitter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./seller_pagerank.gsql\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./seller_pagerank.gsql\n",
    "\n",
    "CREATE QUERY seller_pagerank(BOOL print_accum = FALSE, STRING result_attr = \"\") {\n",
    "    transactions = {Transaction.*};\n",
    "    SumAccum<DOUBLE> @seller_pr;\n",
    "\n",
    "\n",
    "    res = SELECT t FROM transactions:t -(NFT_SOLD_BY)-> NFT_User:u \n",
    "          ACCUM\n",
    "            t.@seller_pr += u.pagerank\n",
    "          POST-ACCUM\n",
    "            IF result_attr != \"\" THEN\n",
    "                t.setAttr(result_attr, t.@seller_pr)\n",
    "            END;\n",
    "    IF print_accum THEN\n",
    "      PRINT res[res.@seller_pr];\n",
    "    END;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = conn.gds.featurizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seller_pagerank'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.installAlgorithm(\"seller_pagerank\", query_path=\"./seller_pagerank.gsql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"result_attr\": \"seller_pr\"}\n",
    "\n",
    "try:\n",
    "    featurizer.runAlgorithm(\"seller_pagerank\", params, feat_name=\"seller_pr\", feat_type=\"DOUBLE\", custom_query=True, schema_name=[\"Transaction\"])\n",
    "except ConnectionError:\n",
    "    featurizer.runAlgorithm(\"seller_pagerank\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./buyer_pagerank.gsql\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./buyer_pagerank.gsql\n",
    "\n",
    "CREATE QUERY buyer_pagerank(BOOL print_accum = FALSE, STRING result_attr = \"\") {\n",
    "    transactions = {Transaction.*};\n",
    "    SumAccum<DOUBLE> @buyer_pr;\n",
    "\n",
    "\n",
    "    res = SELECT t FROM transactions:t -(NFT_BOUGHT_BY)-> NFT_User:u \n",
    "          ACCUM\n",
    "            t.@buyer_pr += u.pagerank\n",
    "          POST-ACCUM\n",
    "            IF result_attr != \"\" THEN\n",
    "                t.setAttr(result_attr, t.@buyer_pr)\n",
    "            END;\n",
    "    IF print_accum THEN\n",
    "      PRINT res[res.@buyer_pr];\n",
    "    END;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buyer_pagerank'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.installAlgorithm(\"buyer_pagerank\", query_path=\"./buyer_pagerank.gsql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"result_attr\": \"buyer_pr\"}\n",
    "\n",
    "try:\n",
    "    featurizer.runAlgorithm(\"buyer_pagerank\", params, feat_name=\"buyer_pr\", feat_type=\"DOUBLE\", custom_query=True, schema_name=[\"Transaction\"])\n",
    "except ConnectionError:\n",
    "    featurizer.runAlgorithm(\"buyer_pagerank\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./kcore_size.gsql\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./kcore_size.gsql\n",
    "\n",
    "CREATE QUERY kcore_size(BOOL print_accum = FALSE, STRING result_attr = \"\") FOR GRAPH KDD_2022_NFT { \n",
    "  MapAccum<INT, SumAccum<INT>> @@kcore_size;\n",
    "  \n",
    "  trans = {Transaction.*};\n",
    "  \n",
    "  res = SELECT t FROM trans:t POST-ACCUM @@kcore_size += (t.k_core -> 1);\n",
    "  \n",
    "  IF print_accum THEN\n",
    "    PRINT @@kcore_size;\n",
    "  END;\n",
    "  \n",
    "  IF result_attr != \"\" THEN\n",
    "    res = SELECT t FROM trans:t POST-ACCUM t.setAttr(result_attr, @@kcore_size.get(t.k_core));\n",
    "  END;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing the queries, it might take a minute\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kcore_size'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.installAlgorithm(\"kcore_size\", query_path=\"./kcore_size.gsql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"result_attr\": \"kcore_size\"}\n",
    "\n",
    "try:\n",
    "    featurizer.runAlgorithm(\"kcore_size\", params, feat_name=\"kcore_size\", feat_type=\"INT\", custom_query=True, schema_name=[\"Transaction\"])\n",
    "except ConnectionError:\n",
    "    featurizer.runAlgorithm(\"kcore_size\", params, custom_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = conn.getSchema(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n"
     ]
    }
   ],
   "source": [
    "train_loader = conn.gds.vertexLoader(\n",
    "    attributes={\"Transaction\": [\"kcore_size\", \"usd_price\", \"seller_pr\", \"buyer_pr\"]},\n",
    "    filter_by=\"train\",\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "nn = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1000, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "opt = Adam(nn.parameters(), lr=0.01)\n",
    "loss = torch.nn.SmoothL1Loss()\n",
    "mae = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_loss(output, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - output) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 348.6691375125772 MAE: 349.10870423535454 R2: -418.2236720564552\n",
      "Loss: 143.34268744743738 MAE: 143.80907596732087 R2: -0.04300043910661476\n",
      "Loss: 143.3426495986486 MAE: 143.80939821412943 R2: -0.042974666122477655\n",
      "Loss: 143.34267037641007 MAE: 143.80941925408706 R2: -0.04297420952840635\n",
      "Loss: 143.34269116702427 MAE: 143.80943305023277 R2: -0.04297374554400174\n",
      "Loss: 143.3427050248632 MAE: 143.8094446794042 R2: -0.04297329858949563\n",
      "Loss: 143.34271578775903 MAE: 143.80945503615305 R2: -0.04297293614184439\n",
      "Loss: 143.34272531422002 MAE: 143.8094629354554 R2: -0.04297266462742479\n",
      "Loss: 143.34273096943159 MAE: 143.80946885543372 R2: -0.04297245127171519\n",
      "Loss: 143.34273438312295 MAE: 143.8094738731487 R2: -0.042972284185918516\n",
      "Loss: 143.34273967074577 MAE: 143.80947605554627 R2: -0.042972177829382556\n",
      "Loss: 143.3427403879294 MAE: 143.8094779423305 R2: -0.04297208753878858\n",
      "Loss: 143.34274287879308 MAE: 143.80948037407148 R2: -0.042972031307991626\n",
      "Loss: 143.34274584520858 MAE: 143.80948133545743 R2: -0.0429720101009482\n",
      "Loss: 143.34274517429486 MAE: 143.80948075451298 R2: -0.04297197475587582\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb#ch0000014?line=2'>3</a>\u001b[0m epoch_mae \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb#ch0000014?line=3'>4</a>\u001b[0m epoch_r2 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb#ch0000014?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb#ch0000014?line=5'>6</a>\u001b[0m     X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(batch[\u001b[39m\"\u001b[39m\u001b[39mTransaction\u001b[39m\u001b[39m\"\u001b[39m][[\u001b[39m\"\u001b[39m\u001b[39mkcore_size\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mseller_pr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbuyer_pr\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parkererickson/kdd2022-tutorial/notebooks/graph_traditional_ml.ipynb#ch0000014?line=6'>7</a>\u001b[0m     y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(batch[\u001b[39m\"\u001b[39m\u001b[39mTransaction\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39musd_price\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/site-packages/pyTigerGraph/gds/dataloaders.py:910\u001b[0m, in \u001b[0;36mBaseLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m--> 910\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_q\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m    911\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kdd2022/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    epoch_loss = 0\n",
    "    epoch_mae = 0\n",
    "    epoch_r2 = 0\n",
    "    for batch in train_loader:\n",
    "        X = torch.tensor(batch[\"Transaction\"][[\"kcore_size\", \"seller_pr\", \"buyer_pr\", \"categoryOneHot\", \"collectionOneHot\"]].values.astype(np.float32))\n",
    "        y = torch.tensor(batch[\"Transaction\"][\"usd_price\"].values.astype(np.float32))\n",
    "        out = nn(X).flatten()\n",
    "        loss_val = loss(out, y)\n",
    "        opt.zero_grad()\n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "        epoch_loss += loss_val.item()\n",
    "        epoch_mae += mae(out, y).item()\n",
    "        epoch_r2 += r2_loss(out, y).item()\n",
    "    print(\"Loss:\", epoch_loss/train_loader.num_batches, \"MAE:\", epoch_mae/train_loader.num_batches, \"R2:\", epoch_r2/train_loader.num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = conn.gds.vertexLoader(\n",
    "    attributes={\"Transaction\": [\"kcore_size\", \"usd_price\", \"seller_pr\", \"buyer_pr\"]},\n",
    "    filter_by=\"test\",\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 92.19558295797795 R2: -0.0536285676854722\n"
     ]
    }
   ],
   "source": [
    "mae_sum = 0\n",
    "r2_sum = 0\n",
    "for batch in test_loader:\n",
    "    X = torch.tensor(batch[\"Transaction\"][[\"kcore_size\", \"seller_pr\", \"buyer_pr\"]].values.astype(np.float32))\n",
    "    y = torch.tensor(batch[\"Transaction\"][\"usd_price\"].values.astype(np.float32))\n",
    "    with torch.no_grad():\n",
    "        out = nn(X).flatten()\n",
    "        mae_sum += mae(out, y).item()\n",
    "        r2_sum += r2_loss(out, y).item()\n",
    "print(\"MAE:\", mae_sum/test_loader.num_batches, \"R2:\", r2_sum/test_loader.num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretLoader = conn.gds.vertexLoader(\n",
    "    attributes={\"Transaction\": [\"kcore_size\", \"usd_price\", \"seller_pr\", \"buyer_pr\"]},\n",
    "    filter_by=\"test\",\n",
    "    num_batches=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(interpretLoader.data[\"Transaction\"][[\"kcore_size\", \"seller_pr\", \"buyer_pr\"]].values.astype(np.float32))\n",
    "y = torch.tensor(interpretLoader.data[\"Transaction\"][\"usd_price\"].values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret Model with Captum\n",
    "https://captum.ai/tutorials/House_Prices_Regression_Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from captum library\n",
    "from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
    "from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(nn)\n",
    "ig_nt = NoiseTunnel(ig)\n",
    "dl = DeepLift(nn)\n",
    "#gs = GradientShap(nn)\n",
    "fa = FeatureAblation(nn)\n",
    "\n",
    "ig_attr_test = ig.attribute(X, n_steps=50)\n",
    "ig_nt_attr_test = ig_nt.attribute(X)\n",
    "dl_attr_test = dl.attribute(X)\n",
    "#gs_attr_test = gs.attribute(X, X_train)\n",
    "fa_attr_test = fa.attribute(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = [\"kcore_size\", \"seller_pr\", \"buyer_pr\"]\n",
    "\n",
    "# prepare attributions for visualization\n",
    "\n",
    "x_axis_data = np.arange(X.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: feature_names[idx], x_axis_data))\n",
    "\n",
    "ig_attr_test_sum = ig_attr_test.detach().numpy().sum(0)\n",
    "ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "\n",
    "ig_nt_attr_test_sum = ig_nt_attr_test.detach().numpy().sum(0)\n",
    "ig_nt_attr_test_norm_sum = ig_nt_attr_test_sum / np.linalg.norm(ig_nt_attr_test_sum, ord=1)\n",
    "\n",
    "dl_attr_test_sum = dl_attr_test.detach().numpy().sum(0)\n",
    "dl_attr_test_norm_sum = dl_attr_test_sum / np.linalg.norm(dl_attr_test_sum, ord=1)\n",
    "\n",
    "fa_attr_test_sum = fa_attr_test.detach().numpy().sum(0)\n",
    "fa_attr_test_norm_sum = fa_attr_test_sum / np.linalg.norm(fa_attr_test_sum, ord=1)\n",
    "\n",
    "lin_weight = nn.lin1.weight[0].detach().numpy()\n",
    "y_axis_lin_weight = lin_weight / np.linalg.norm(lin_weight, ord=1)\n",
    "\n",
    "width = 0.14\n",
    "legends = ['Int Grads', 'Int Grads w/SmoothGrad','DeepLift', 'Feature Ablation', 'Weights']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Comparing input feature importances across multiple algorithms and learned weights')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 16\n",
    "plt.rc('font', size=FONT_SIZE)            # fontsize of the text sizes\n",
    "plt.rc('axes', titlesize=FONT_SIZE)       # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=FONT_SIZE)       # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
    "\n",
    "ax.bar(x_axis_data, ig_attr_test_norm_sum, width, align='center', alpha=0.8, color='#eb5e7c')\n",
    "ax.bar(x_axis_data + width, ig_nt_attr_test_norm_sum, width, align='center', alpha=0.7, color='#A90000')\n",
    "ax.bar(x_axis_data + 2 * width, dl_attr_test_norm_sum, width, align='center', alpha=0.6, color='#34b8e0')\n",
    "ax.bar(x_axis_data + 4 * width, fa_attr_test_norm_sum, width, align='center', alpha=1.0, color='#49ba81')\n",
    "ax.bar(x_axis_data + 5 * width, y_axis_lin_weight, width, align='center', alpha=1.0, color='grey')\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data + 0.5)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.legend(legends, loc=3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('kdd2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58e1c476a485e41cfbe41589baaac1849e255b67efca409760b0ec34d7f4c191"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
